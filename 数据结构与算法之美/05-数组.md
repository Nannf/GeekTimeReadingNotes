#### 前言

1. 知道数据结构和算法的产生背景
2. 知道数据结构和算法的优点和不足
3. 知道数据结构和算法能解决什么问题，以及哪些场景会出现这些问题。





首先，数组是一个数据结构，即组织数据的一种方式。



这个只是一种组织数据的方式，属于逻辑上的概念，有没有一个物理上的介质？比如是基于内存还是基于磁盘。

- 最后的指令都是cpu调度
- cpu调度指令，指令会访问数据，指令和数据都存储在内存中。
- 但是有些数据，比如数据库的索引，redis存储的数据，这部分数据是要持久化到磁盘上的，所以，这部分数据要使用一种方式持久化到磁盘上，然后再读取到内存中，供cpu访问。
- 综上： 数据结构发挥作用的地方是内存，可以持久化到磁盘保存。



cpu在访问数据时，需要指定地址。

当我们有多个数据时，如何访问这多个数据就有了多种选择。



我们试着来给出数组的定义

**数组，是一种线性表数据结构，用一组连续的内存空间，来存储一组具有相同类型的数据。**

定义中有几个关键点：

- 线性表
- 连续的内存空间
- 一组相同类型。

何为线性表：

任何在线上的元素，只有前后两个方向。故名线性表。

![img](https://static001.geekbang.org/resource/image/b6/77/b6b71ec46935130dff5c4b62cf273477.jpg)



非线性表就意味中元素之间的关系不是简单的前后关系，比如树和图。



随机访问：连续的内存空间+相同的数据类型。

如果我要访问数组中第k个元素，我只需知道数组的第一个元素的地址，加上数组中存储的数据类型的大小 * k。

随机访问 ≠ 查找的时间复杂度是O(1);



知道了数组的数据存储模型，下面就要看下数组的访问接口。

1. 查找

   就算是二分查找，时间复杂度也是O(logN);

2. 插入和删除

   因为数组的空间是连续的，我们插入和删除的操作会涉及到移动数据的操作。

   而移动的次数是跟你插入和删除的位置有关的。极端情况是一次不移动，和移动所有的数据。

   平均时间复杂度是O(N);

3. 插入删除的优化

   1. 拿插入举例，如果我们无需维护数据的顺序，只是把数组当作一个存储数据的集合，那么其实数据的位置是没有关系的。我们在k位置的插入，可以把k位置原本的值放到最后，然后插入新的值。**快排** 我看了下后面的快排相关，这个感觉有点牵强附会。可能我还没领悟到其中的深意。
   2. 删除而言，可以先标记，后删除。即jvm的标记删除。



java中不存在数组越界导致的缓冲区溢出问题。

c语言会有类似的问题。



#### 容器与数组

ArrayList 与 数组。

- ArrayList 只能存储包装类型，使用基本类型时，需要不停的拆包与装包。这个损耗的性能比我们想象的大很多，我之前写一个多线程，性能瓶颈就是出在这边
- ArrayList 简单易用，做了很多封装，比如自动扩容等。
- 综上，对性能要求不高的业务开发使用容器，对性能要求高的场景，比如网络传输等还是使用数组。



#### 数组为啥从0编号

- 当时c语言是这样实现的，第k个元素表示这个元素基于第一个元素的偏移。
  - a[k] = a[0] + k * len;
- 后面的c++、java都是为了降低转换语言的成本而一脉相承。
- matlab就是从1开始





#### 课后思考

1. 前面我基于数组的原理引出 JVM 的标记清除垃圾回收算法的核心理念。我不知道你是否使用 Java 语言，理解 JVM，如果你熟悉，可以在评论区回顾下你理解的标记清除垃圾回收算法。

   - 哪些内存需要回收，可达性分析发现当前的对象到GCRoot都没有路径的时候
   - 怎么回收
   - 什么时候回收

   会有垃圾碎片。



2. 前面我们讲到一维数组的内存寻址公式，那你可以思考一下，类比一下，二维数组的内存寻址公式是怎样的呢？

   `a[k]_address = base_address + k * type_size`

   二维数组，先定位到一维数组的下标，那个里面存储的是二维数组的初始地址.

   ~~`a[m][n]_address=a[0]_base_address+k * type_size + n * type_size`~~

   **二维数组**的存储空间是连续的，虽然我们可以按照二维数组是一维数组，一维数组的元素是另一个一维数组。

   但是实际上，数据空间是连续的，即假设`a[0][0]的地址是base_address`那么我访问`a[m][n]中的a[i][j]`=

   `base_address+(i*n+j)*type_size`

