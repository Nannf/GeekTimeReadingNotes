- 大数据量
- rdb fork耗时
  - 耗时的原因是因为单机的数据量太大，占用内存
  - fork是因为rdb为了不阻塞主线程，而fork的一个子线程
  - fork的原因是因为子线程可以共享主线程的内存空间，完成数据的拷贝
  - 共享内存空间意味着fork的耗时和内存成正比
  - 如果我们选择N台机器，这样每个机器都只需存储1/N数据的大小，这样fork的时间会缩小
  - 但是随着时间的推移，不可避免的要进行扩容，之前的hash算法就会失效，
    - 失效的原因是，之前有N个实例，无论是哪种hash算法，最后一定会mod上这个N，这样完成了存取操作
    - 当我们新增实例了之后，取的时候如果按照实例数来取，大概率都是取不到的，这个就是问题
    - 这个需要解决的问题



果然，重点就是在论述，横向新增实例的时候，客户端如何响应的问题。这其实就是一致性哈希。



- mod的对象不是实例的个数，而是一个名为hash槽个数的东西，这个hash槽的个数，按照一致性hash的理论，hash槽的个数要远大于实例的个数
- 每个实例和hash slot的对应关系有两种，一个是均分，一个是手动设置，但是手动设置的时候要保证把所有的hash slot全部分配完
  - 当实例之间连接的时候，会交换自己的slot信息，这样当客户端连接上来的时候，就知道实例和slot之间的对应关系了
  - 
- 变动就发生在新增或者删除实例，或者实例不变，但是因为每个实例的压力不均而重新进行负载均衡的时候
- 客户端请求一个key，客户端计算这个key所在的slot之后，然后按照自己保存的实例和slot之间的对应关系，给对应的实例发送请求
  - 此时，如果已经完成了rehash，那么老实例会发一个moved命令给客户端，客户端会修改slot到新的实例，然后发送请求到新的实例
  - 如果slot数据较多，只迁移了部分，且要访问的部分在新实例，那么会发生一个ASKING给客户端，客户端会往新实例发送请求，注意，这个和上面的区别是，当客户端再次访问这个key时，还是会访问老实例的。

