#### 前言

我们要怎么判断一个数据库是不是正常在运行呢? 

我们为什么要问这个问题呢？因为主备切换主要发生在HA系统检测到主库出问题了的时候主动发生的切换。



我觉得是要对这个正常的边界进行一个明确。



读完本章之后发现就是这个边界的问题，导致了不同的判断方式。



#### 主库进程还在，就是好的

select 就是在这个边界下产生的。

我们看如下的一段sql序列

```mysql
set global innodb_thread_concurrency=3;

CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

 insert into t values(1,1)
```

![img](https://static001.geekbang.org/resource/image/35/55/35076dd3d0a0d44d22b76d2a29885255.png)

###### innodb_thread_concurrency

这个参数控制的是innodb并发线程的上限。当达到这个上限的时候，如果服务器接收到新的查询请求，会被放到等待队列，直到有查询线程返回。当是0的时候，表示不限制查询并发线程数，服务器的资源有限，这个不限制会导致cpu进行频繁的上下文切换，没有起到加速的效果。

###### 并发连接和并发查询

show processlist 结果可以有数千个连接，这个是并发连接，但是当前处于执行状态的语句才是并发查询。

并发连接数是存放在内存中，并发查询耗费的是cpu。



当线程进入锁等待之后，并发线程数会减一。

这个其实很好理解，并发线程出现的目的是为了加速查询的效率，极端情况下，我一个线程持有一个行锁不释放，后续来的线程恰好都要修改这一行，而这些查询线程数量达到了并发线程的上限，这样数据库服务器就停止对外提供服务，这样cpu的使用率很低，但是没办法处理请求。

这个是不合理的，所以要减一。



###### 问题

这个问题是当并发线程达到上限后，因为select 1并没有实际的查表操作，所以检测不出这种异常。





##### 数据库没有达到并发查询的上限

这个的操作是查一张实际的表。这个存在的目的就是为了解决select 1 解决不了的并发线程满的问题。



但是我们查哪张表好呢？能查业务表吗？不大好吧，不好在哪呢？万一有锁怎么办，什么锁能阻挠select ，我来想想，行锁可以吗，查询会被锁住吗？卧槽我忘记了，我猜测是不会的，除非显式的加了表锁，这个我明天去验证一下。

所以我们可以专门建一个空表，每次都查询这个空表来判断并发线程有没有到达设置的阈值的场景。



###### 问题

我们知道空间满了之后，binlog这些都没办法写了，但是查询语句是不记录binlog的，所以这个解决不了空间满的问题。



##### 数据库可以修改

查询不记录binlog，会漏检产生binlog的情况，那我们就在刚刚查询的表里新插入一条数据。

那我们就在那个表里插入数据。作者提出一个观点：

1. 如果是一主一备的场景，检测的话是主库和备库都需要检测
2. 备库一般是只读，不产生binlog，但是更新数据，备库可以产生binlog
3. 由此得出结论，主备库会冲突，导致备库不在同步主库

我们知道主备库会因为什么冲突导致不在同步？插入一条当前库已经存在的记录，更新会吗？显然不会，那为什么说这个会导致主备不在同步呢？

我想了下这个冲突可能不太准确，与其说陷入冲突，不如说会造成死循环，死循环的开始就是主库和备库更新的记录不一样。

假设表里就一个字段 last_check_time.主库的运行时间和备库有那么点差异，这个会导致死循环的产生；

1. 假设A先执行，发给B
2. B也执行了，在B执行结束之后，收到了A发来的binlog,并在接受的时候，把自己的binlog发送给了A
3. B执行了A的binlog，
4. A执行了B的binlog。

我还是没想明白在什么一个场景下这个会有冲突



我忽略了循环复制的问题，当B执行收到A的binlog的时候，虽然生成了binlog，但是binlog的server_id是A的，所以这个修改在A那边不会重复执行。

这样造成的影响就是A和B互换了时间，这个会有啥影响，搞不明白。

这个不是我们关注的重点，重点是查询不写binlog，如果磁盘满的话，服务也是不可用，检测不出来，所以我们需要进行插入操作。



###### 超时问题

超时多用于写入时判断多久未返回就判定数据库不可用。

超时问题的场景多发生于IO压力很大，其实很多的响应已经很慢了，但是因为我们更新的内容所需的io很小，导致我们的更新很快就返回，但是实际上服务处理的大部分请求都已经不可用了。



顺着这个思路，我们已经优化完成了，但是最终的结论我们发现也是充满着随机性的。相当于我们把mysql当成一个黑盒，我们往里扔不同的东西，看看它给我们的回应，我们来猜测它有多深，



我们也可以深入mysql内部，当一个服务不可用的时候，它的具体表现是啥，如果我们能到找一个不可用状态的定义，一旦检测到系统处于这个状态，立马提示不可用，岂不美哉。



但是我们看到作者的思路，发现并不是要全盘否定，推翻我们的扔石头行为，而是我们的扔石头行为解决不了的随机性问题，它主要是来解决这个问题的，算是内外合璧。



我们扔石头，会卡在随机性上，随机性的问题是在我们没办法检测磁盘利用率上，基于此，我们只要在内部解决这个磁盘利用率的问题即可。



##### 磁盘利用率的分析

磁盘利用率的问题其实不是问题，而是磁盘利用率高了之后，会导致我们的请求的io变慢，所以磁盘利用率分析的最终是要落在io的时间上。

io的时间是存储在这张库中: performance_schema; 表名是file_summary_by_event_name

![img](https://static001.geekbang.org/resource/image/75/dd/752ccfe43b4eab155be17401838c62dd.png)



COUNT_STAR: 所有io的总次数。

下面的是耗时，但是是皮秒（1皮秒=10^-12次方秒）



COUNT_READ:从redolog中读取了几次，以及读取的字节数

下面的WRITE是写操作。

下面的MISC就是对磁盘的fsync的统计。



我们知道做这些统计是需要额外的记录的，会损耗不小的性能（大概是10%）

但是我们可以从里面的MAX_TIME设置来设置阈值来检查我们的IO等待时间的问题。







