#### 前言

”饮鸩止渴“，渴虽解，人已死。



通读一遍，作者举出了一些常见的数据库性能下降的场景，并给出了一些解决方案。

本文一遍阅读下来感受是有压力，文章中都是实际存在的场景，我把自己代入到场景下发现自己好像脑袋一片空白，数据量都挺大，问题也都挺严重，百度似乎也没用。

感觉到这一讲开始就已经是实战篇了，需要查漏补缺，真正的用起来，加油。



#### 背景

- 业务高峰期
- mysql服务器没有响应
- 短期内，临时性提升性能
- 有损的



##### 短连接风暴

###### 问题的原因

- 正常的短连接是，客户端和服务器建立连接，执行很少的语句之后就断开连接，然后使用时重复上面的步骤
- 短连接的问题就是这个建立连接的过程，除了三次握手之外，还要做登录权限判断等，比较耗时。
  - 耗时的影响在同时请求的数量多了之后慢慢显现
  - 因为这些操作都是cpu调度执行的，如果cpu执行了这个操作，就会减少实际执行的查询的操作
  - 基于上面的分析，我们知道数据库设置了一个最大连接数的概念，就是为了让数据库尽可能的为更多的提供服务，却不至于让自己的拥塞住。
  - 但是这个就有问题了，就是这个最大连接数是一定的，但是如果同时请求的一旦多起来，那么就会连接不上，此时对客户端而言，直观的现象就是数据库服务不可用。

###### 问题的解决措施

1. 增大数据库连接数量
   - 正如我们在上文分析的，这个会适得其反，如果服务器资源使用率（cpu，磁盘等）不高的情况下，会有效果，但是更多的时候，增加了连接数量，而cpu等硬件不同步升级，在cpu时间片轮转调度的情况下，会有更少的时间被分配给那些真正的sql执行语句，这会使那些连接的释放更加缓慢，久而久之，就会发现新增的连接数也被占满了，然后继续加连接数，继续占用系统资源，这一恶性循环。
2. 把那些占着连接不使用的连接给kill 掉
   - 有风险，风险主要体现在，有的连接已经开启了事务，然后在等待，有些没有，那些开启事务的连接，一旦被kill，就会回滚之前的操作，这个对业务的影响比较大
   - 如果是那些没有事务的连接，但是我们不能保证客户端在每次使用连接之前都会去判断连接是否还存在，如果不去判断的话，你把它的连接给kill了。会影响这个业务的正常使用。
3. 减少连接的处理过程，重启数据库，把跳过权限验证的开关打开，这样就减少了连接过程中的一些额外操作，但是风险巨大，不推荐使用。



我们综合来看，如果请求量很大的话，如果仅仅是读请求，可以通过读备份库来做到读写分离，如果是写请求较多呢？写请求会导致性能问题吗？这个我们之后再说，我们先来看看读请求。

我们来看看读请求，暂时不考虑使用主备库来优化的操作，仅仅就单机而言。

读请求一般慢，慢在哪呢？

- 索引没设计好
- sql语句没写好
- mysql选错了索引。

因为我们知道，数据库最耗时的操作就是全表扫描，然后返回所有字段。索引也是基于此而产生的一种优化，所以，所有查询的问题，基本都可以归到索引的问题。

##### 索引没设计好

这种更新一下就好了，现在的数据库都支持Online DDL了，后面作者以一个主库一个备库为例，来描述整个操作，比如先关闭从库的binlog之类的，至于为什么这样做，不知道，现在我们知道有这么个东西，等实际用到了再说。



##### sql语句没写好

我们在17章举出了几种类型，总结说来都是在查询语句上显式或隐式的使用了函数，导致了索引的快速定位功能失效（并不是不走索引）。

这种的解决措施是query_rewrite功能（5.7以后提供）就是在解析sql语句的时候，发现满足某种格式的sql，都转成另外一种。

```mysql

mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");

call query_rewrite.flush_rewrite_rules();
```

![img](https://static001.geekbang.org/resource/image/47/8a/47a1002cbc4c05c74841591d20f7388a.png)

可以通过这个来判断重写有没有生效。

##### mysql选错索引

我们在第九章的时候论证过这个问题，简单的可以使用 force index 指定要使用的索引这个也可以通过query_rewrite语句来写，让优化器不在计算选择什么索引。

前两个原因，没有合适的索引，和sql语句没写好，是可以在上线前就规避掉的。具体的可以如下操作：

1. 打开慢查询日志，把慢查询的阈值时间设置为0，这样所有的查询都会记录到日志中
2. 同步正式环境的相关数据到测试表中，进行查询测试
3. 观看examine rows和预期的是否一致。



##### QPS突增问题

如果是查询突增，这时候服务端熔断，限流解决会更好些。

但本文只讨论数据库端能给出的解决方案。

而且本文讨论的情况是业务的bug导致的qps突增的问题，至于什么问题呢？我写了一个死循环，不停的执行一个耗时很久的查询，这算是bug把，反正类似的都行。

1. 如果是新功能导致的bug，这里有个概念就是白名单，可以把该业务从白名单上划掉。白名单就是用户名+ip，这个新功能应该是使用了新的用户名或者ip。
2. 如果新功能使用的是全新的数据库用户，那么直接使用管理员用户把这个用户删除
3. 如果这个新功能和之前的功能耦合在一起（这是最常见的），把引起问题的语句使用之前提到的query_rewrite功能给重写。
   1. 误伤较大，极其不推荐使用。



提到了**虚拟化、白名单机制、业务账号分离**



##### 小结

数据库连接我们在编写的时候使用前都要有重连机制。