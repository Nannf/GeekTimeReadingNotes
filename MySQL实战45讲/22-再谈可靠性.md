#### 前言

本文的主体部分都在介绍binlog和redolog的落盘逻辑。

冲突的双方是速度和可靠性。

可靠性的讨论，我们先假设只要落到磁盘上，就可以保证数据一定不会丢失，当然磁盘也有坏道这些故障，在磁盘上也有raid算法来保证磁盘上数据的可靠性，这个不在本文的考虑范围内。

既然为了可靠性，数据一定要落盘，而落盘是因为随机写磁盘总是很慢的。

文件系统为了解决这个问题，新增了一个缓存，就是一个内存，不是cpu级别的缓存。

程序写内存是很快的。

在这个思路下，我们先试举两种极端情况。

1. 只考虑性能

   - 所有的操作，只在内存上，等系统空闲下来之后，在刷盘。

   问题

   - 内存的容量可能不够
   - 无法应对系统重启和服务重启

2. 只考虑可靠性

   - 每个操作都必须落盘

   问题

   - 随机操作磁盘非常慢。

本文的所有讨论就是在解决性能和可靠性之间的冲突，试图在两者之间找到一个平衡点满足我们的需求。



#### binlog的写入逻辑

写入，指的是写入到磁盘中。binlog不是顺序存储，是随机存储的，写入磁盘就意味着随机i/o，就意味着我们不能每条binlog语句都直接落盘。

不能直接落盘，又不像redolog那样有一块连续的空间来存储，我们只有考虑内存了，这个内存块名为**binlog Cache**。当我们遇到内存来作为临时存储的时候，我们总是要考虑到内存空间的有限性，当我们要存储的内容超过一定阈值的时候，我们不可避免的要借助磁盘。

一个事务binlog是不能被拆开的，无论多大，必须一次性写入。如果容许多阶段写入的话，那我们什么时候返回binlog写入成功呢？这是一个问题，接着就是根据binlog的语义我们还原时，我们要怎么去执行呢？难道我先执行事务A的一部分语句，然后执行事务B的一部分语句，如果是这样的话，事务之间的语句难免会相互影响，而导致数据的不一致（所有的数据不一致，都是语句实际执行的表的数据和使用binlog语句恢复数据库的数据不一致）。而你此时说，我们可以遍历所有的binlog，把一个事务的所有语句都找全了再执行，这跟一次性写入的效果不是一样的吗，你这并没有什么优化，而且还带来了很多额外的问题。

![img](https://static001.geekbang.org/resource/image/9e/3e/9ed86644d5f39efb0efec595abb92e3e.png)

如图所示，当一个事务的所有binlog全部写完之后，我们会把它write到binlog files中，然后情况binlog cache，binlogfiles是page cache，是操作系统中的文件系统提供的一个类似内存样的空间，所以写这一步是非常快的。

这个文件是多个事务共享的，那同时写的时候是如何保证不乱的呢？如果让我来实现我会怎么做。

如果我们要解决这个问题，势必要先明白这个是不是一个问题，就是同一个事务的binlog必须在这个上面连续吗？我们反证法证明，假设不是，那么我们为什么还要保证binlog必须一次性全部写入呢？

那么我们如何保证多个事务之间的写能并行执行呢？难道写内存是顺序执行的？感觉不大可能，这个地方的细节太多，不看到源码我没办法妄自揣度。先记下来，当我们以后知道的时候再回来补充。

总之，就是一个事务里的binlog，必须先全部的写入到binlog cache中，这个cache由内存和磁盘两部分组成，当binlog的数据太大时，可能会把数据转移到磁盘上。当事务执行完成后，会同步到由操作系统文件系统提供的一个缓存 page cache，这个文件是多个事务共享的。此时如果**操作系统**重启，注意，不是mysql服务器重启，那么这个内容就会丢失，因为没有持久化到磁盘上。

持久化到磁盘上是fsync做的。这个做的时机是参数配置的。

参数名为 sync_binlog

当为0时，只执行write操作，不执行fsync。这种不是脑瘫吗？那内存满了怎么办。

当为1时，每次write都fsync，最安全，但是耗时最久。

当为N，N>1,没执行一次write操作之后，就执行fsync操作，这个就是速度和可靠性的考量。假设N=1000，最坏情况下，当我们执行了1000次write操作后，服务器打算执行fsync刷盘时，操作系统重启了，这会导致这一千次的binlog丢失。



#### redolog的写入逻辑

我们再14章日志和索引的番外篇一文中提及了redolog的落盘逻辑。

redolog在写盘的时候跟binlog一样，虽然是顺序io,但是mysql服务器可能觉得还是慢了。

有些东西我现在都忘记了，redolog其实没有跟binlog一样记录了改之前和改之后的内容，它只是记载了在哪个数据页上进行了哪个改动，必须把数据页加载进内存和redolog进行一次merge才能得到最新的数据页。

而redolog的落盘也不是我分析的那样，因为速度的原因，是因为一个事务还没commit的时候，我总要有个地方存储，这个地方就是 redolog buffer。

这是当时的分析，但是作者在这里给出了新的解释，就是存在没commit就刷盘的redologbuffer

![img](https://static001.geekbang.org/resource/image/9d/d4/9d057f61d3962407f413deebc80526d4.png)

这个和binlog是一致的。照binlog的类推逻辑innodb_flush_log_at_trx_commit控制。

1. 当该值是0的时候，redolog只保存在redologbuffer中
2. 当为1的时候，每次都落盘
3. 当为2的时候，每次都只把数据刷到FS page cache中。



InnoDb后台有个线程，每隔1s，就把redolog buffer中的数据调用write 写入 page cache 然后再调用 fsync持久化到磁盘。

除了这个后台的线程，还有其他的方式。

1. redolog buffer 空间占用innodb_log_buffer_size一半的时候，后台线程会主动写盘，如果这个事务没有提交，那么这个写盘是只write到page cache中。
2. 并行事务提交。这个的场景是事务A写了部分数据到redolog buffer 中，但是没有提交，事务B提交了，如果此时innodb_flush_log_at_trx_commit设置的是1，那么所有的redolog buffer 会持久化到磁盘。

