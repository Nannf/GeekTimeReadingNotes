#### 前言

本文的主体部分都在介绍binlog和redolog的落盘逻辑。

冲突的双方是速度和可靠性。

可靠性的讨论，我们先假设只要落到磁盘上，就可以保证数据一定不会丢失，当然磁盘也有坏道这些故障，在磁盘上也有raid算法来保证磁盘上数据的可靠性，这个不在本文的考虑范围内。

既然为了可靠性，数据一定要落盘，而落盘是因为随机写磁盘总是很慢的。

文件系统为了解决这个问题，新增了一个缓存，就是一个内存，不是cpu级别的缓存。

程序写内存是很快的。

在这个思路下，我们先试举两种极端情况。

1. 只考虑性能

   - 所有的操作，只在内存上，等系统空闲下来之后，在刷盘。

   问题

   - 内存的容量可能不够
   - 无法应对系统重启和服务重启

2. 只考虑可靠性

   - 每个操作都必须落盘

   问题

   - 随机操作磁盘非常慢。

本文的所有讨论就是在解决性能和可靠性之间的冲突，试图在两者之间找到一个平衡点满足我们的需求。



#### binlog的写入逻辑

写入，指的是写入到磁盘中。binlog不是顺序存储，是随机存储的，写入磁盘就意味着随机i/o，就意味着我们不能每条binlog语句都直接落盘。

不能直接落盘，又不像redolog那样有一块连续的空间来存储，我们只有考虑内存了，这个内存块名为**binlog Cache**。当我们遇到内存来作为临时存储的时候，我们总是要考虑到内存空间的有限性，当我们要存储的内容超过一定阈值的时候，我们不可避免的要借助磁盘。

一个事务binlog是不能被拆开的，无论多大，必须一次性写入。如果容许多阶段写入的话，那我们什么时候返回binlog写入成功呢？这是一个问题，接着就是根据binlog的语义我们还原时，我们要怎么去执行呢？难道我先执行事务A的一部分语句，然后执行事务B的一部分语句，如果是这样的话，事务之间的语句难免会相互影响，而导致数据的不一致（所有的数据不一致，都是语句实际执行的表的数据和使用binlog语句恢复数据库的数据不一致）。而你此时说，我们可以遍历所有的binlog，把一个事务的所有语句都找全了再执行，这跟一次性写入的效果不是一样的吗，你这并没有什么优化，而且还带来了很多额外的问题。

![img](https://static001.geekbang.org/resource/image/9e/3e/9ed86644d5f39efb0efec595abb92e3e.png)

如图所示，当一个事务的所有binlog全部写完之后，我们会把它write到binlog files中，然后情况binlog cache，binlogfiles是page cache，是操作系统中的文件系统提供的一个类似内存样的空间，所以写这一步是非常快的。

这个文件是多个事务共享的，那同时写的时候是如何保证不乱的呢？如果让我来实现我会怎么做。

如果我们要解决这个问题，势必要先明白这个是不是一个问题，就是同一个事务的binlog必须在这个上面连续吗？我们反证法证明，假设不是，那么我们为什么还要保证binlog必须一次性全部写入呢？

那么我们如何保证多个事务之间的写能并行执行呢？难道写内存是顺序执行的？感觉不大可能，这个地方的细节太多，不看到源码我没办法妄自揣度。先记下来，当我们以后知道的时候再回来补充。

总之，就是一个事务里的binlog，必须先全部的写入到binlog cache中，这个cache由内存和磁盘两部分组成，当binlog的数据太大时，可能会把数据转移到磁盘上。当事务执行完成后，会同步到由操作系统文件系统提供的一个缓存 page cache，这个文件是多个事务共享的。此时如果**操作系统**重启，注意，不是mysql服务器重启，那么这个内容就会丢失，因为没有持久化到磁盘上。

持久化到磁盘上是fsync做的。这个做的时机是参数配置的。

参数名为 sync_binlog

当为0时，只执行write操作，不执行fsync。这种不是脑瘫吗？那内存满了怎么办。

当为1时，每次write都fsync，最安全，但是耗时最久。

当为N，N>1,没执行一次write操作之后，就执行fsync操作，这个就是速度和可靠性的考量。假设N=1000，最坏情况下，当我们执行了1000次write操作后，服务器打算执行fsync刷盘时，操作系统重启了，这会导致这一千次的binlog丢失。



#### redolog的写入逻辑

我们再14章日志和索引的番外篇一文中提及了redolog的落盘逻辑。

redolog在写盘的时候跟binlog一样，虽然是顺序io,但是mysql服务器可能觉得还是慢了。

有些东西我现在都忘记了，redolog其实没有跟binlog一样记录了改之前和改之后的内容，它只是记载了在哪个数据页上进行了哪个改动，必须把数据页加载进内存和redolog进行一次merge才能得到最新的数据页。

而redolog的落盘也不是我分析的那样，因为速度的原因，是因为一个事务还没commit的时候，我总要有个地方存储，这个地方就是 redolog buffer。

这是当时的分析，但是作者在这里给出了新的解释，就是存在没commit就刷盘的redologbuffer

![img](https://static001.geekbang.org/resource/image/9d/d4/9d057f61d3962407f413deebc80526d4.png)

这个和binlog是一致的。照binlog的类推逻辑innodb_flush_log_at_trx_commit控制。

1. 当该值是0的时候，redolog只保存在redologbuffer中
2. 当为1的时候，每次都落盘
3. 当为2的时候，每次都只把数据刷到FS page cache中。



InnoDb后台有个线程，每隔1s，就把redolog buffer中的数据调用write 写入 page cache 然后再调用 fsync持久化到磁盘。

除了这个后台的线程，还有其他的方式。

1. redolog buffer 空间占用innodb_log_buffer_size一半的时候，后台线程会主动写盘，如果这个事务没有提交，那么这个写盘是只write到page cache中。
2. 并行事务提交。这个的场景是事务A写了部分数据到redolog buffer 中，但是没有提交，事务B提交了，如果此时innodb_flush_log_at_trx_commit设置的是1，那么所有的redolog buffer 会持久化到磁盘。

我们再第二章的时候知道，一个更新语句再提交的时候，涉及到两阶段提交，一个是redolog 先置于prepare阶段，然后写binlog，然后把redolog置为commit状态。

我们再redolog 处于prepare状态的时候，其实redolog，已经写入到redologbuffer中了，如果innodb_flush_log_at_trx_commit设置为1，那么此时的redolog已经落盘了。我们当时分析的时候知道，当崩溃恢复时，如果有redolog处于pp状态的，需要找有没有对应的binlog，就是这个逻辑。

当我们redolog处于pp状态的时候如果落盘了，那么再commit状态的时候就无需落盘了。其实这有个问题，就是commit对pp状态做了改动吗？还是改动了的，最起码有个状态位改了。如果有改动的内存这部分是没落盘的，还在文件系统提供的缓存中。

##### 双一

双一指的是binlog写入时的落盘控制参数，和redolog的落盘控制参数都设置为一，那么每次写入的时候，会落两次盘。

哦吼，一次更新写两次盘，那性能不得慢死。

这就用到了组提交。

其实这个逻辑很简单，就是我落盘的操作都是一致的，我单个 提交慢的话，我就批量提交，至于如何实现批量提交，我们再来看看。

其实这个我举得是有问题的，组提交的逻辑是，我们知道redolog是一个环，我们每次记录的时候，会有一个长度，比如第一次写入50字节，第二次写入120字节，依次类推。这里有个LSN（日志逻辑序列号），第一次写完之后就是50，第二次写完之后就是170，依次类推。

作者给出的解释是，当第一个事务开始写盘的时候，带过去的是目前最新的lsn的值，即170。

这边我昨天忽视的一点就是 redolog是一块连续的磁盘空间，而且我们知道当我们使用系统调用写磁盘的时候，一次写很长，和分很多次写一样长的性能是有差距的，这个要涉及到系统调用层面的知识了，我们可以先不管，我能想到的是，每次进行系统调用都涉及到用户态和内核态的转换，还涉及到系统中断，已经磁盘系统和mysql服务的交互等等操作，就跟三次握手一样，我们使用长连接，减少了每次连接带来的性能损耗。

这个就是优化写磁盘的方法了。

那如果我们的优化点不是顺序i/o，而是类似于tcp连接一样的消耗，那么我们的binlog也是可以优化的。

就是让binlog多等一会儿再写。

我们知道再写日志的时候，

1. redolog处于prepare
2. 写binlog
3. redolog处于commit
4. 结束

这四步操作。

我们上面的分析知道，binlog是先写binlog cache的，然后会写到磁盘上。

因为redolog再prepare的时候是分两步的。

先写redologbuffer 再落盘。

![img](https://static001.geekbang.org/resource/image/5a/28/5ae7d074c34bc5bd55c82781de670c28.png)

具体怎么控制的，我们不知道，反正就是通过拖延时间，让binlogfile上积累一些需要落盘的数据，然后统一落盘。

我们现在假设有十个事务，同时需要修改数据，那么他们会同时的往redolog中写数据，然后write进redolog的缓存，此时对每个事务而言都没有直接落盘，而是开始写binlog cache等写完之后，开始调用redolog的落盘。

这个其实就是互相给对方拖延时间，因为write的时候都是写内存，很快的，redolog先写了，然后本来按照配置，应该立马落盘的，但是这样达不到组提交的优化了，那我只好等一会儿，减少磁盘的压力，等的过程中，可以把binlog的write操作给执行了，等binlog的write执行完成之后，redologbuffer中可能已经积攒了一些等待刷盘的任务了，这时候调用fsync刷盘，这个过程中，binlog那边一直再积累，等redolog刷盘成功之后，再刷binlog，完成了组提交。

不过这个中间就是一个时间差的问题，比如第三步redolog写盘，因为redolog是顺序io.所以争取来的时间可能非常有限，binlog的组提交表现的不尽如人意。

一个解决方案就是我们人为的暂停。

可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。

1. binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。

二者的关系是或有一个满足了即可。



这边作者给出了binlog也是顺序写，这个我们暂时持保留意见。



此时如果有个问题，就是mysql服务器有i/o瓶颈，你要如何优化。

1. 设置我们刚刚说的binlog的延迟刷盘参数，让binlog多积攒一些，提交组提交的效果。这个的影响是增加了请求的响应时间，并不会丢数据
2. 设置binlog的sync_binlog积攒刷盘的次数高一些，这种的影响是服务器断电，会丢失数据。
3. innodb_flush_log_at_trx_commit设置为2，等待后台的线程慢慢刷，这样的影响是服务器断电会丢失数据。，

永远不要设置innodb_flush_log_at_trx_commit=0，这样的话，数据库服务重启都会丢失数据，而且write进fscache中是内存，性能不差多少。